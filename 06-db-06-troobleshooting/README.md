## Задача 1
>Вы как инженер поддержки решили произвести данную операцию:
>    напишите список операций, которые вы будете производить для остановки запроса пользователя
>    предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

Сперва определить id операции:

		db.currentOp()

Далеее убить данный запрос с помощью метода:

		db.killOp()

Для того чтобы решать подобные проблемы систематически, нужно
включить профилировщик для медленных запросов, допустим на порог 50мс

		db.setProfilingLevel(1, 50)

Далее можно проанализировать историю, выявить и локализовать неэффективные запросы. 
Для этого стоит регулярно просматривать самые тяжелые операции на предмет ошибки.
Так можно найти все операции длиннее 100 мс.

		db.system.profile.find( { millis : { $gt : 100 } } );

Ну и далее с помощью explain исследовать проблемные запросы



## Задача 2

>Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
>Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и 
>увеличивается пропорционально количеству реплик сервиса.
>
>При масштабировании сервиса до N реплик вы увидели, что:
>    сначала рост отношения записанных значений к истекшим
>    Redis блокирует операции записи
>
>Как вы думаете, в чем может быть проблема?


Возможно в работе используются команды, которые блокируют клиентов, например такие как SAVE, KEYS.
Использование этих команд является распространенным источником задержки.
Или медленные команды, увеличивающие задержку, такие как SORT, LREM, SUNION
Нужно проводить анализ с использованием режима: Redis Slow Log


## Задача 3

>Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы, пользователи начали жаловаться на ошибки вида:
		
		InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '

>Как вы думаете, почему это начало происходить и как локализовать проблему?
>Какие пути решения данной проблемы вы можете предложить?

Иногда форма «during query» возникает, когда миллионы строк отправляются как часть одного или нескольких запросов.
А так как у нас ГИС система, то это весьма вероятный сценарий данной ошибки.

Следует попробовать увеличить net_read_timeout со значения по умолчанию 30 секунд до 60 секунд или дольше, 
чтобы было достаточно времени для завершения передачи данных.

Также есть вероятность что в ГИС системе геометрические данные хранятся в виде BLOB и может быть так, 
что максимальный размер значений превышает допустимое в системе. 
Попробуем увеличить значение max_allowed_packet.


## Задача 4

>Перед выполнением задания ознакомтесь со статьей Common PostgreSQL errors из блога Percona.
>Вы решили перевезти гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объемом данных лучше, чем MySQL.
>После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

		postmaster invoked oom-killer

>Как вы думаете, что происходит?
>Как бы вы решили данную проблему?

Когда у сервера или процесса заканчивается память, Linux предлагает 2 пути решения: 
обрушить всю систему или завершить процесс (приложение), который съедает память. 
Лучше, конечно, завершить процесс и спасти ОС от аварийного завершения. 
В двух словах, Out-Of-Memory Killer — это процесс, который завершает приложение, чтобы спасти ядро от сбоя.
Если в системе мало памяти и освободить ее невозможно, вызывается функция out_of_memory, она убивает процесс,
который съедает памяти больше других, поэтому выбор падает на главный процесс postgreSQL.

Для решения проблемы я бы внес изменения в поведение ядра ОС, рекомендованные для Postgress:
vm.overcommit_memory=2
overcommit_ratio=(исходя из количества RAM на сервере)

Это не гарантирует, что OOM-Killer перестанет убивать PostgreSQL, но снизит вероятность принудительного завершения.
